{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the CSV file into a DataFrame\n",
    "tv= pd.read_csv(\"Traffic_Violations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the first 5 rows of the DataFrame\n",
    "print(tv.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for missing values\n",
    "print(tv.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping irrelevant columns\n",
    "irrelevant_columns = ['SeqID', 'Location', 'Latitude', 'Longitude', 'Geolocation']\n",
    "tv = tv.drop(irrelevant_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Date Of Stop column to datetime type\n",
    "tv['Date Of Stop'] = pd.to_datetime(tv['Date Of Stop'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Time Of Stop column to datetime type\n",
    "tv['Time Of Stop'] = pd.to_datetime(tv['Time Of Stop'], format='%H:%M:%S').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling missing values in categorical columns with 'Unknown'\n",
    "categorical_columns = ['Agency', 'SubAgency', 'Charge', 'Article', 'Race', 'Gender', 'Driver City', 'Driver State', 'DL State', 'Arrest Type']\n",
    "tv[categorical_columns] = tv[categorical_columns].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling missing values in numerical columns with mean or appropriate value\n",
    "tv['Year'] = tv['Year'].fillna(tv['Year'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing one-hot encoding for categorical variables (if needed)\n",
    "#For example, if 'Violation Type' is a categorical variable, you can encode it using one-hot encoding:\n",
    "#tv = pd.get_dummies(tv, columns=['Violation Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the updated DataFrame\n",
    "print(tv.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics\n",
    "print(tv.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the 'Year' variable\n",
    "plt.figure(facecolor='lightgrey')\n",
    "plt.hist(tv['Year'], bins=10, color='lightgreen')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a bar plot of the top 10 most frequent 'Violation Type'\n",
    "top_violation_types = tv['Violation Type'].value_counts().head(10)\n",
    "colors = ['pink', 'purple', 'orange']\n",
    "\n",
    "plt.bar(top_violation_types.index, top_violation_types.values,color=colors)\n",
    "plt.xlabel('Violation Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Top 10 Violation Types')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of 'Alcohol' vs. 'Property Damage'\n",
    "fig, pt = plt.subplots(figsize=(8, 6))\n",
    "pt.set_facecolor('skyblue') \n",
    "pt.scatter(tv['Alcohol'], tv['Property Damage'], color='red')\n",
    "pt.set_xlabel('Alcohol')\n",
    "pt.set_ylabel('Property Damage')\n",
    "pt.set_title('Alcohol vs. Property Damage')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date Of Stop' to datetime\n",
    "tv['Date Of Stop'] = pd.to_datetime(tv['Date Of Stop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract day of the week, month, and hour features\n",
    "tv['Day Of Week'] = tv['Date Of Stop'].dt.dayofweek\n",
    "tv['Month'] = tv['Date Of Stop'].dt.month\n",
    "tv['Hour'] = pd.to_datetime(tv['Time Of Stop'], format='%H:%M:%S').dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode 'Violation Type'\n",
    "tv_encoded = pd.get_dummies(tv, columns=['Violation Type'], prefix='Violation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tv_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tv_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Alcohol' and 'Property Damage' columns to numeric values\n",
    "tv['Alcohol'] = tv['Alcohol'].map({'Yes': 1, 'No': 0})\n",
    "tv['Property Damage'] = tv['Property Damage'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interaction feature between 'Alcohol' and 'Property Damage'\n",
    "tv['Alcohol_PropertyDamage'] = tv['Alcohol'] * tv['Property Damage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current year\n",
    "current_year = pd.to_datetime('today').year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the age of the driver\n",
    "tv['Age'] = current_year - tv['Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin 'Age' into categories\n",
    "bins = [0, 18, 30, 50, np.inf]\n",
    "labels = ['Teen', 'Young Adult', 'Adult', 'Senior']\n",
    "tv['Age_Category'] = pd.cut(tv['Age'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tv_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tv_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Accident' column to numeric values\n",
    "tv_encoded['Accident'] = tv_encoded['Accident'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tv_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tv_encoded.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the features (X) and the target variable (y)\n",
    "features = [ 'Alcohol', 'Accident', 'Gender']\n",
    "target = 'Violation_Citation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tv_encoded[features], tv_encoded[target], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Alcohol', 'Accident', 'Gender', 'Violation_Citation']\n",
    "specific_columns_data = tv_encoded[selected_columns]\n",
    "\n",
    "print(specific_columns_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Alcohol' column to numeric values\n",
    "tv_encoded['Alcohol'] = tv_encoded['Alcohol'].map({'No': 0, 'Yes': 1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Alcohol', 'Accident', 'Gender', 'Violation_Citation']\n",
    "specific_columns_data = tv_encoded[selected_columns]\n",
    "\n",
    "print(specific_columns_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Gender' column to numeric values\n",
    "tv_encoded['Gender'] = tv_encoded['Gender'].map({'M': 1, 'F': 2, 'U':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Alcohol', 'Accident', 'Gender', 'Violation_Citation']\n",
    "specific_columns_data = tv_encoded[selected_columns]\n",
    "\n",
    "print(specific_columns_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Specify the features (X) and the target variable (y)\n",
    "features = [ 'Alcohol', 'Accident', 'Gender']\n",
    "target = 'Violation_Citation'\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tv_encoded[features], tv_encoded[target], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = tv_encoded.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='magma', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values from specific columns\n",
    "columns_to_clean = ['Alcohol', 'Accident', 'Gender', 'Violation_Citation']\n",
    "tv_encoded_cleaned = tv_encoded.dropna(subset=columns_to_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with float64 values in specific columns\n",
    "columns_to_check = ['Alcohol', 'Accident', 'Gender', 'Violation_Citation']\n",
    "tv_encoded_cleaned = tv_encoded_cleaned.dropna(subset=columns_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for float64 and NaN values in specific columns\n",
    "columns_to_check = ['Alcohol', 'Accident', 'Gender', 'Violation_Citation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values\n",
    "nan_values = tv_encoded_cleaned[columns_to_check].isnull().sum()\n",
    "print(\"NaN Values:\")\n",
    "print(nan_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for float64 values\n",
    "float_values = tv_encoded_cleaned[columns_to_check].apply(lambda x: x.dtype == 'float64')\n",
    "print(\"Float64 Values:\")\n",
    "print(float_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Model Training & Evaluation (Logistic Regression/Decision Tree/Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Specify the features (X) and the target variable (y)\n",
    "features = ['Alcohol', 'Accident', 'Gender']\n",
    "target = 'Violation_Citation'\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tv_encoded[features], tv_encoded[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create an instance of the Decision Tree model\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Decision Tree Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(\"Precision:\", precision_dt)\n",
    "print(\"Recall:\", recall_dt)\n",
    "print(\"F1 score:\", f1_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create an instance of the Random Forest model\n",
    "random_forest = RandomForestClassifier()\n",
    "# Fit the model to the training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1 score:\", f1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a meshgrid of feature values\n",
    "x1_min, x1_max = X_train.iloc[:, 0].min() - 1, X_train.iloc[:, 0].max() + 1\n",
    "x2_min, x2_max = X_train.iloc[:, 1].min() - 1, X_train.iloc[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.1),\n",
    "                       np.arange(x2_min, x2_max, 0.1))\n",
    "xx3 = np.full_like(xx1, X_train['Gender'].mean())  # Add the mean value of 'Gender' as a constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the three features\n",
    "X_meshgrid = np.c_[xx1.ravel(), xx2.ravel(), xx3.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the meshgrid\n",
    "Z = logreg.predict(X_meshgrid)\n",
    "Z = Z.reshape(xx1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the decision boundaries\n",
    "plt.contourf(xx1, xx2, Z, alpha=0.3)\n",
    "plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train, edgecolors='k')\n",
    "plt.xlabel('Alcohol')\n",
    "plt.ylabel('Accident')\n",
    "plt.title('Logistic Regression Decision Boundaries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the decision tree\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_tree(decision_tree, feature_names=features, filled=True)\n",
    "plt.title('Decision Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting one of the decision trees from the random forest\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_tree(random_forest.estimators_[0], feature_names=features, filled=True)\n",
    "plt.title('Random Forest - Decision Tree')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df95319d8ce4e1d89f5365ae10992bc1f65da593082b1d264e8f529830ec2f02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
